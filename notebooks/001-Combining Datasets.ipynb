{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4cd417c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f5512a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a6e37f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read Data/yellow_tripdata_2023-11.parquet\n",
      "Successfully read Data/yellow_tripdata_2023-12.parquet\n",
      "Error reading Data/yellow_tripdata_2024-01 (1).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Error reading Data/yellow_tripdata_2024-01 (2).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Error reading Data/yellow_tripdata_2024-01 (3).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Error reading Data/yellow_tripdata_2024-01 (4).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Error reading Data/yellow_tripdata_2024-01 (5).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Error reading Data/yellow_tripdata_2024-01 (6).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Error reading Data/yellow_tripdata_2024-01 (7).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Error reading Data/yellow_tripdata_2024-01 (8).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Error reading Data/yellow_tripdata_2024-01 (9).parquet: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.\n",
      "Combined Parquet file saved as 'combined_dataset.parquet'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import os\n",
    "\n",
    "# List of Parquet file paths\n",
    "parquet_files = [\n",
    "    'Data/yellow_tripdata_2023-11.parquet',\n",
    "    'Data/yellow_tripdata_2023-12.parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (1).parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (2).parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (3).parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (4).parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (5).parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (6).parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (7).parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (8).parquet',\n",
    "    'Data/yellow_tripdata_2024-01 (9).parquet'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "for file in parquet_files:\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(file):\n",
    "            print(f\"File not found: {file}\")\n",
    "            continue\n",
    "\n",
    "        # Attempt to read the Parquet file\n",
    "        df = pd.read_parquet(file)\n",
    "        dataframes.append(df)\n",
    "        print(f\"Successfully read {file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "# Check if any dataframes were successfully read\n",
    "if dataframes:\n",
    "    try:\n",
    "        # Concatenate all dataframes into one large dataframe\n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        \n",
    "        # Save the combined dataframe to a new Parquet file\n",
    "        combined_df.to_parquet('combined_dataset.parquet', engine='pyarrow', index=False)\n",
    "        print(\"Combined Parquet file saved as 'combined_dataset.parquet'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error concatenating or saving dataframes: {e}\")\n",
    "else:\n",
    "    print(\"No dataframes were read successfully. Combined file was not created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d30d023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0         2  2024-01-01 00:57:55   2024-01-01 01:17:43              1.0   \n",
      "1         1  2024-01-01 00:03:00   2024-01-01 00:09:36              1.0   \n",
      "2         1  2024-01-01 00:17:06   2024-01-01 00:35:01              1.0   \n",
      "3         1  2024-01-01 00:36:38   2024-01-01 00:44:56              1.0   \n",
      "4         1  2024-01-01 00:46:51   2024-01-01 00:52:57              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0           1.72         1.0                  N           186            79   \n",
      "1           1.80         1.0                  N           140           236   \n",
      "2           4.70         1.0                  N           236            79   \n",
      "3           1.40         1.0                  N            79           211   \n",
      "4           0.80         1.0                  N           211           148   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0             2         17.7    1.0      0.5        0.00           0.0   \n",
      "1             1         10.0    3.5      0.5        3.75           0.0   \n",
      "2             1         23.3    3.5      0.5        3.00           0.0   \n",
      "3             1         10.0    3.5      0.5        2.00           0.0   \n",
      "4             1          7.9    3.5      0.5        3.20           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \n",
      "0                    1.0         22.70                   2.5          0.0  \n",
      "1                    1.0         18.75                   2.5          0.0  \n",
      "2                    1.0         31.30                   2.5          0.0  \n",
      "3                    1.0         17.00                   2.5          0.0  \n",
      "4                    1.0         16.10                   2.5          0.0  \n"
     ]
    }
   ],
   "source": [
    "# Path to the combined Parquet file\n",
    "parquet_file_path = 'combined_dataset.parquet'\n",
    "\n",
    "# Load the Parquet file into a Pandas DataFrame\n",
    "large_df = pd.read_parquet(parquet_file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to confirm\n",
    "print(large_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d67f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as 'local_file.csv'\n"
     ]
    }
   ],
   "source": [
    "# Save as a CSV file\n",
    "large_df.to_csv('local_file.csv', index=False)\n",
    "\n",
    "print(\"File saved as 'local_file.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the csv file\n",
    "\n",
    "# Path to the CSV file\n",
    "file_path = 'local_file.csv'  # Replace with your file's name or full path\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc5286e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
